import gradio as gr
from PIL import Image
import io
import zlib
import base91
import numpy as np
from math import sqrt, floor
import librosa
import soundfile as sf

# è‡ªå®šä¹‰å“ˆåŸºç±³å­—å…¸ (ä¿æŒä¸å˜)
CUSTOM_DICT = {
    'A': 'å“ˆ', 'B': 'è›¤', 'C': 'åŸº', 'D': 'é¸¡', 'E': 'å‡ ', 'F': 'å­£', 'G': 'é›†', 'H': 'å¯„',
    'I': 'å‰', 'J': 'æ£˜', 'K': 'è„Š', 'L': 'ç±³', 'M': 'å¯†', 'N': 'å’ª', 'O': 'è«', 'P': 'æ‘¸',
    'Q': 'è†œ', 'R': 'æŠ¹', 'S': 'æ¼ ', 'T': 'ç£¨', 'U': 'é™Œ', 'V': 'å¯', 'W': 'ç”·', 'X': 'å—',
    'Y': 'å–ƒ', 'Z': 'å¤', 'a': 'é‚£', 'b': 'å“ª', 'c': 'å‘', 'd': 'çº³', 'e': 'æ²¡', 'f': 'ç¾',
    'g': 'æ¯', 'h': 'ç»¿', 'i': 'è·¯', 'j': 'é¹¿', 'k': 'å½•', 'l': 'ä¸‹', 'm': 'è±†', 'n': 'é€—',
    'o': 'æ–—', 'p': 'å¤š', 'q': 'å“†', 'r': 'è·º', 's': 'æœµ', 't': 'å•Š', 'u': 'é˜¿', 'v': 'è¥¿',
    'w': 'ç³»', 'x': 'å™¶', 'y': 'å˜', 'z': 'å‘€', '0': 'å‹', '1': 'é›…', '2': 'äºš', '3': 'ä¸«',
    '4': 'åº“', '5': 'å“­', '6': 'é…·', '7': 'å¥¶', '8': 'ä¹ƒ', '9': 'å¥ˆ', '!': 'è€', '#': 'é¾™',
    '$': 'å’¯', '%': 'æ›¼', '&': 'æ³¢', '*': 'æ¼«', '(': 'å•µ', ')': 'å¶', '+': 'æ¬§', ',': 'å—',
    '"': 'é©¬', '.': 'å˜›', '/': 'é‡Œ', ':': 'åŠ›', '<': 'åˆ©', '=': 'ç†', '>': 'ä¸½',
    '?': 'å†', '@': 'ä¹Ÿ', '[': 'è€¶', '~': 'å¤§', ']': 'å“’', '^': 'è¾¾', '_': 'å—’', '`': 'ä¸',
    '{': 'å¸ƒ', '|': 'æ‰“', '}': 'å“‡', 'AA': 'å‘µ', 'BB': 'æŒ–', '9!': 'ccb', 'DD': 'å¸¦æ‰‹æœº', 'EE': 'å…´å¥‹å‰‚', 'FF': 'æ“é€¼', 'GG': 'ä¸€æ®µ', ':}': 'wow'
}
# åè½¬å­—å…¸ç”¨äºè§£ç  (ä¿æŒä¸å˜)
REVERSE_DICT = {v: k for k, v in CUSTOM_DICT.items()}

# --- å®šä¹‰æœ€å¤§é¢ç§¯å¸¸é‡ ---
MAX_PIXEL_AREA = 16384

# --- éŸ³é¢‘å¤„ç†å¸¸é‡ ---
AUDIO_SAMPLE_RATE = 22050  # ç”¨äºé‡é‡‡æ ·çš„ç›®æ ‡é‡‡æ ·ç‡
AUDIO_N_FFT = 2048
AUDIO_HOP_LENGTH = 512
AUDIO_MAX_DURATION = 10.0 # æœ€å¤§å¤„ç†æ—¶é•¿ (ç§’)ï¼Œé˜²æ­¢è¿‡å¤§æ–‡ä»¶

# --- å›¾ç‰‡å¤„ç†å‡½æ•° (ä¿æŒä¸å˜) ---

def smart_resize(image, target_area=MAX_PIXEL_AREA):
    """æ™ºèƒ½ç¼©æ”¾å›¾åƒã€‚"""
    img = Image.fromarray(image.astype('uint8'), 'RGB')
    original_w, original_h = img.size
    original_area = original_w * original_h
    if original_area <= target_area:
        print(f"Image is small/large enough ({original_w}x{original_h}), processing at original size.")
        return img, (original_w, original_h)
    else:
        scale_factor = sqrt(target_area / original_area)
        new_w = max(1, floor(original_w * scale_factor))
        new_h = max(1, floor(original_h * scale_factor))
        resized_img = img.resize((new_w, new_h), Image.LANCZOS)
        print(f"Image is large ({original_w}x{original_h}), resized to ({new_w}x{new_h}) based on area.")
        return resized_img, (original_w, original_h)

def adaptive_compress(image_pil, quality=15):
    """æ ¹æ®å›¾åƒç‰¹å¾è‡ªé€‚åº”å‹ç¼©"""
    img = image_pil
    w, h = img.size
    np_img = np.array(img)
    diff_x = np.abs(np_img[:, 1:] - np_img[:, :-1]).mean()
    diff_y = np.abs(np_img[1:, :] - np_img[:-1, :]).mean()
    complexity = (diff_x + diff_y) / 2

    if w * h < 5000:
        adjusted_quality = max(quality, 20)
        colors = 256
    elif complexity < 5:
        adjusted_quality = quality + 5
        colors = 64
    elif complexity > 30:
        adjusted_quality = max(quality - 5, 5)
        colors = 128
    else:
        adjusted_quality = quality
        colors = 128

    if colors < 256:
        img = img.quantize(colors=colors, method=Image.MEDIANCUT, dither=Image.FLOYDSTEINBERG)
        img = img.convert('RGB')

    buffer = io.BytesIO()
    img.save(buffer, format='WEBP', quality=adjusted_quality, method=6)
    compressed_img = buffer.getvalue()
    return compressed_img, adjusted_quality, colors

def image_to_text(image, quality=15):
    """å°†å›¾ç‰‡è½¬æ¢ä¸ºæ–‡æœ¬ç¼–ç """
    if image is None:
         return "é”™è¯¯: æœªæä¾›å›¾ç‰‡", ""
    try:
        original_size = image.shape[1], image.shape[0]
        processed_img_pil, orig_size = smart_resize(image, target_area=MAX_PIXEL_AREA)
        compressed_data, used_quality, used_colors = adaptive_compress(processed_img_pil, quality)
        zlib_compressed = zlib.compress(compressed_data, level=9)
        base91_str = base91.encode(zlib_compressed)

        text_data = base91_str
        for pattern in sorted(CUSTOM_DICT.keys(), key=len, reverse=True):
            text_data = text_data.replace(pattern, CUSTOM_DICT[pattern])

        size_prefix = f"å“ˆåŸºç‰‡:{orig_size[0]}x{orig_size[1]}|"
        lines = [text_data[i:i+24] for i in range(0, len(text_data), 24)]
        formatted_text = "\n".join(lines)
        return size_prefix + formatted_text, "" # å›¾ç‰‡ç¼–ç ä¸è¿”å›å‚æ•°ä¿¡æ¯
    except Exception as e:
        gr.Error(f"å›¾ç‰‡ç¼–ç å¤±è´¥: {e}")
        return f"é”™è¯¯: {e}", ""

def text_to_image(text_data):
    """å°†æ–‡æœ¬ç¼–ç è¿˜åŸä¸ºå›¾ç‰‡"""
    if not text_data or not text_data.strip():
        gr.Warning("è¾“å…¥çš„åŠ å¯†æ–‡æœ¬ä¸ºç©ºã€‚")
        return None, "é”™è¯¯: è¾“å…¥ä¸ºç©º"

    param_info_str = "è§£ç ä¸­..."
    orig_w = "æœªçŸ¥"
    orig_h = "æœªçŸ¥"
    processed_w = "æœªçŸ¥"
    processed_h = "æœªçŸ¥"

    clean_text_for_decoding = text_data
    if text_data.startswith("å“ˆåŸºç‰‡:"):
        parts = text_data.split("|", 1)
        if len(parts) == 2:
            size_info_part = parts[0]
            text_data_body = parts[1]
            try:
                _, size_str = size_info_part.split(":", 1)
                orig_w_str, orig_h_str = size_str.split("x", 1)
                orig_w = int(orig_w_str)
                orig_h = int(orig_h_str)
                param_info_str = f"åŸå§‹å°ºå¯¸: {orig_w}x{orig_h}\n"
            except (ValueError, IndexError) as e:
                 gr.Warning(f"åŠ å¯†æ–‡æœ¬ä¸­çš„å°ºå¯¸ä¿¡æ¯æ ¼å¼ä¸æ­£ç¡®: {e}")
                 param_info_str = "å°ºå¯¸ä¿¡æ¯è§£æå¤±è´¥\n"
            clean_text_for_decoding = text_data_body
        else:
            gr.Warning("åŠ å¯†æ–‡æœ¬æ ¼å¼é”™è¯¯ï¼šå‘ç°'å“ˆåŸºç‰‡:'å‰ç¼€ä½†ç¼ºå°‘åˆ†éš”ç¬¦'|'ã€‚")
            param_info_str = "æ ¼å¼é”™è¯¯: ç¼ºå°‘åˆ†éš”ç¬¦\n"

    clean_text = clean_text_for_decoding.replace("\n", "").replace(" ", "")
    if not clean_text:
        error_msg = "é”™è¯¯: å¤„ç†åçš„åŠ å¯†æ–‡æœ¬ä¸»ä½“ä¸ºç©ºã€‚"
        gr.Error(error_msg)
        return None, param_info_str + error_msg

    temp_text = clean_text
    for char, pattern in REVERSE_DICT.items():
        temp_text = temp_text.replace(char, pattern)
    clean_text = temp_text

    try:
        zlib_data = base91.decode(clean_text)
    except Exception as e:
        error_msg = f"Base91è§£ç å¤±è´¥: {str(e)}"
        gr.Error(error_msg)
        return None, param_info_str + error_msg

    try:
        webp_data = zlib.decompress(zlib_data)
    except Exception as e:
        error_msg = f"zlibè§£å‹å¤±è´¥: {str(e)}ã€‚è¾“å…¥æ–‡æœ¬å¯èƒ½å·²æŸåæˆ–ä¸å®Œæ•´ã€‚"
        gr.Error(error_msg)
        return None, param_info_str + error_msg

    try:
        img = Image.open(io.BytesIO(webp_data))
        img = img.convert('RGB')
        processed_w, processed_h = img.size
        final_param_info = param_info_str + f"å¤„ç†åå°ºå¯¸: {processed_w}x{processed_h}\nè§£ç æˆåŠŸ!"
        return np.array(img), final_param_info
    except Exception as e:
        error_msg = f"æ— æ³•é‡å»ºå›¾åƒ: {str(e)}"
        gr.Error(error_msg)
        return None, param_info_str + error_msg

# --- éŸ³é¢‘å¤„ç†å‡½æ•° ---

def audio_to_text(audio_tuple, quality=15):
    """å°†éŸ³é¢‘è½¬æ¢ä¸ºæ–‡æœ¬ç¼–ç """
    if audio_tuple is None:
        return "é”™è¯¯: æœªæä¾›éŸ³é¢‘", ""
    try:
        # audio_tuple æ˜¯ (sample_rate, audio_data)
        orig_sr, audio_data = audio_tuple
        # ç¡®ä¿æ˜¯å•å£°é“
        if audio_data.ndim > 1:
            audio_data = audio_data[:, 0] # å–ç¬¬ä¸€ä¸ªå£°é“

        # é™åˆ¶æ—¶é•¿
        max_samples = int(AUDIO_MAX_DURATION * orig_sr)
        if len(audio_data) > max_samples:
             gr.Info(f"éŸ³é¢‘è¿‡é•¿ï¼Œä»…å¤„ç†å‰ {AUDIO_MAX_DURATION} ç§’ã€‚")
             audio_data = audio_data[:max_samples]

        # é‡é‡‡æ ·
        audio_float = audio_data.astype(np.float32)
        if np.max(np.abs(audio_data)) > 0:
            audio_float = audio_float / np.max(np.abs(audio_data))
        audio_resampled = librosa.resample(y=audio_float, orig_sr=orig_sr, target_sr=AUDIO_SAMPLE_RATE)

        # è½¬æ¢ä¸ºé¢‘è°±å›¾ (ä¾‹å¦‚ Mel é¢‘è°±)
        mel_spec = librosa.feature.melspectrogram(y=audio_resampled, sr=AUDIO_SAMPLE_RATE, n_fft=AUDIO_N_FFT, hop_length=AUDIO_HOP_LENGTH)
        # è½¬æ¢ä¸ºå¯¹æ•°å¹…åº¦
        log_mel_spec = librosa.power_to_db(mel_spec, ref=np.max)

        # åºåˆ—åŒ–ä¸ºå­—èŠ‚
        spec_bytes = log_mel_spec.tobytes()

        # å‹ç¼©
        zlib_compressed = zlib.compress(spec_bytes, level=9)
        # Base91ç¼–ç 
        base91_str = base91.encode(zlib_compressed)

        # åº”ç”¨è‡ªå®šä¹‰å­—å…¸æ›¿æ¢
        text_data = base91_str
        for pattern in sorted(CUSTOM_DICT.keys(), key=len, reverse=True):
            text_data = text_data.replace(pattern, CUSTOM_DICT[pattern])

        # æ·»åŠ æ—¶é•¿ä¿¡æ¯å‰ç¼€
        duration = len(audio_resampled) / AUDIO_SAMPLE_RATE
        duration_prefix = f"å¤§ç‹—å«:{duration:.2f}s|"

        # æ ¼å¼åŒ–è¾“å‡º
        lines = [text_data[i:i+24] for i in range(0, len(text_data), 24)]
        formatted_text = "\n".join(lines)

        param_info = f"éŸ³é¢‘æ—¶é•¿: {duration:.2f}s\né‡‡æ ·ç‡: {AUDIO_SAMPLE_RATE}Hz\nFFTå¤§å°: {AUDIO_N_FFT}\nHopé•¿åº¦: {AUDIO_HOP_LENGTH}"
        return duration_prefix + formatted_text, param_info
    except Exception as e:
        gr.Error(f"éŸ³é¢‘ç¼–ç å¤±è´¥: {e}")
        return f"é”™è¯¯: {e}", ""

def text_to_audio(text_data):
    """å°†æ–‡æœ¬ç¼–ç è¿˜åŸä¸ºéŸ³é¢‘ (ç®€åŒ–ç‰ˆï¼Œä»…æ¼”ç¤ºæµç¨‹)"""
    if not text_data or not text_data.strip():
        gr.Warning("è¾“å…¥çš„åŠ å¯†æ–‡æœ¬ä¸ºç©ºã€‚")
        return None, "é”™è¯¯: è¾“å…¥ä¸ºç©º"

    param_info_str = "è§£ç ä¸­..."
    duration = "æœªçŸ¥"

    clean_text_for_decoding = text_data
    if text_data.startswith("å¤§ç‹—å«:"):
        parts = text_data.split("|", 1)
        if len(parts) == 2:
            size_info_part = parts[0]
            text_data_body = parts[1]
            try:
                _, duration_str = size_info_part.split(":", 1)
                duration = duration_str.replace("s", "") # ç§»é™¤ 's'
                duration = float(duration)
                param_info_str = f"éŸ³é¢‘æ—¶é•¿: {duration:.2f}s\n"
            except (ValueError, IndexError) as e:
                 gr.Warning(f"åŠ å¯†æ–‡æœ¬ä¸­çš„æ—¶é•¿ä¿¡æ¯æ ¼å¼ä¸æ­£ç¡®: {e}")
                 param_info_str = "æ—¶é•¿ä¿¡æ¯è§£æå¤±è´¥\n"
            clean_text_for_decoding = text_data_body
        else:
            gr.Warning("åŠ å¯†æ–‡æœ¬æ ¼å¼é”™è¯¯ï¼šå‘ç°'å¤§ç‹—å«:'å‰ç¼€ä½†ç¼ºå°‘åˆ†éš”ç¬¦'|'ã€‚")
            param_info_str = "æ ¼å¼é”™è¯¯: ç¼ºå°‘åˆ†éš”ç¬¦\n"

    clean_text = clean_text_for_decoding.replace("\n", "").replace(" ", "")
    if not clean_text:
        error_msg = "é”™è¯¯: å¤„ç†åçš„åŠ å¯†æ–‡æœ¬ä¸»ä½“ä¸ºç©ºã€‚"
        gr.Error(error_msg)
        return None, param_info_str + error_msg

    temp_text = clean_text
    for char, pattern in REVERSE_DICT.items():
        temp_text = temp_text.replace(char, pattern)
    clean_text = temp_text

    try:
        zlib_data = base91.decode(clean_text)
    except Exception as e:
        error_msg = f"Base91è§£ç å¤±è´¥: {str(e)}"
        gr.Error(error_msg)
        return None, param_info_str + error_msg

    try:
        spec_bytes = zlib.decompress(zlib_data)
    except Exception as e:
        error_msg = f"zlibè§£å‹å¤±è´¥: {str(e)}ã€‚è¾“å…¥æ–‡æœ¬å¯èƒ½å·²æŸåæˆ–ä¸å®Œæ•´ã€‚"
        gr.Error(error_msg)
        return None, param_info_str + error_msg

    try:
        # ä»å­—èŠ‚é‡å»ºé¢‘è°±å›¾å½¢çŠ¶ (è¿™é‡Œéœ€è¦çŸ¥é“åŸå§‹å½¢çŠ¶ï¼Œç®€åŒ–å¤„ç†)
        # å®é™…åº”ç”¨ä¸­å¯èƒ½éœ€è¦åœ¨ç¼–ç æ—¶å­˜å‚¨é¢‘è°±å›¾çš„å½¢çŠ¶ä¿¡æ¯
        # è¿™é‡Œå‡è®¾ä¸€ä¸ªå…¸å‹çš„å½¢çŠ¶ (ä¾‹å¦‚ 128 é¢‘æ®µ, 44 ä¸ªæ—¶é—´å¸§)
        # æ³¨æ„ï¼šè¿™ä¼šå¯¼è‡´è§£ç åçš„éŸ³é¢‘ä¸åŸå§‹éŸ³é¢‘ä¸å®Œå…¨ä¸€è‡´ï¼Œä»…ç”¨äºæ¼”ç¤º
        spec_shape = (128, 44) # ç¤ºä¾‹å½¢çŠ¶
        log_mel_spec_flat = np.frombuffer(spec_bytes, dtype=np.float32)
        if log_mel_spec_flat.size != np.prod(spec_shape):
             # å°è¯•æ ¹æ®å­—èŠ‚æ•°æ¨æ–­ (å¯èƒ½ä¸å‡†ç¡®)
             expected_size = len(spec_bytes) // 4 # float32 is 4 bytes
             spec_shape = (128, expected_size // 128) # ç®€å•ä¼°ç®—
             if spec_shape[0] * spec_shape[1] * 4 != len(spec_bytes):
                  raise ValueError("æ— æ³•æ¨æ–­é¢‘è°±å›¾å½¢çŠ¶")

        log_mel_spec = log_mel_spec_flat.reshape(spec_shape)

        # è½¬æ¢å›å¹…åº¦è°±
        mel_spec = librosa.db_to_power(log_mel_spec)

        # Griffin-Lim ç®—æ³•é‡å»ºéŸ³é¢‘
        audio_reconstructed = librosa.feature.inverse.mel_to_audio(mel_spec, sr=AUDIO_SAMPLE_RATE, n_fft=AUDIO_N_FFT, hop_length=AUDIO_HOP_LENGTH)

        # è½¬æ¢ä¸º Gradio éœ€è¦çš„æ ¼å¼ (é‡‡æ ·ç‡, éŸ³é¢‘æ•°æ®)
        # Gradio æœŸæœ› int16 ç±»å‹çš„æ•°æ®
        audio_int16 = (audio_reconstructed * 32767).astype(np.int16)

        final_param_info = param_info_str + f"é‡‡æ ·ç‡: {AUDIO_SAMPLE_RATE}Hz\nè§£ç æˆåŠŸ (æ³¨æ„: ä¸ºæ¼”ç¤ºï¼Œå¯èƒ½ä¸åŸéŸ³é¢‘ä¸åŒ)!"
        return (AUDIO_SAMPLE_RATE, audio_int16), final_param_info
    except Exception as e:
        error_msg = f"æ— æ³•é‡å»ºéŸ³é¢‘: {str(e)}"
        gr.Error(error_msg)
        return None, param_info_str + error_msg

# --- æ™ºèƒ½è§£ç å‡½æ•° ---
def smart_decode(text_data):
    """æ ¹æ®å‰ç¼€æ™ºèƒ½åˆ¤æ–­å¹¶è°ƒç”¨è§£ç å‡½æ•°"""
    if not text_data or not text_data.strip():
        return None, "é”™è¯¯: è¾“å…¥ä¸ºç©º", None

    clean_text = text_data.strip()
    if clean_text.startswith("å“ˆåŸºç‰‡:"):
        img, param_info = text_to_image(clean_text)
        return img, param_info, None # è¿”å›å›¾ç‰‡, å‚æ•°ä¿¡æ¯, éŸ³é¢‘(æ— )
    elif clean_text.startswith("å¤§ç‹—å«:"):
        audio, param_info = text_to_audio(clean_text)
        return None, param_info, audio # è¿”å›å›¾ç‰‡(æ— ), å‚æ•°ä¿¡æ¯, éŸ³é¢‘
    else:
        # å¦‚æœæ²¡æœ‰æ˜ç¡®å‰ç¼€ï¼Œå¯ä»¥å°è¯•åˆ¤æ–­æˆ–æŠ¥é”™
        # è¿™é‡Œç®€å•æŠ¥é”™
        gr.Warning("æ— æ³•è¯†åˆ«æ–‡æœ¬ç±»å‹ï¼Œè¯·ç¡®ä¿æ–‡æœ¬ä»¥ 'å“ˆåŸºç‰‡:' æˆ– 'å¤§ç‹—å«:' å¼€å¤´ã€‚")
        return None, "é”™è¯¯: æ— æ³•è¯†åˆ«çš„æ–‡æœ¬ç±»å‹", None

# --- å­—æ•°ç»Ÿè®¡å‡½æ•° ---
def count_chars(text):
    """è®¡ç®—æ–‡æœ¬ä¸­çš„å­—ç¬¦æ•°ï¼ˆä¸åŒ…æ‹¬æ¢è¡Œç¬¦ï¼‰"""
    if not text:
        return 0
    return len(text.replace('\n', ''))

# ==================== Gradio ç•Œé¢å®šä¹‰ ====================
with gr.Blocks(title="å“ˆåŸºç±³å›¾ç‰‡/éŸ³é¢‘ç¼–ç å™¨", theme=gr.themes.Soft()) as app:
    gr.Markdown("## ğŸ± å“ˆåŸºç±³å›¾ç‰‡/éŸ³é¢‘ç¼–ç å™¨ ")
    gr.Markdown("ä¸Šä¼ å›¾ç‰‡æˆ–éŸ³é¢‘ï¼Œæ™ºèƒ½å¤„ç†å¹¶è½¬æ¢ä¸ºæœ‰è¶£çš„æ–‡å­—ç¼–ç ï¼")

    # åŠŸèƒ½é€‰æ‹©
    mode_selector = gr.Radio(
        choices=["å›¾ç‰‡ç¼–ç ", "éŸ³é¢‘ç¼–ç "],
        value="å›¾ç‰‡ç¼–ç ",
        label="é€‰æ‹©åŠŸèƒ½"
    )

    with gr.Row():
        with gr.Column():
            # å›¾ç‰‡è¾“å…¥ç»„ä»¶
            input_image = gr.Image(
                label="ä¸Šä¼ å›¾ç‰‡", 
                type="numpy", 
                visible=True
            )
            
            # éŸ³é¢‘è¾“å…¥ç»„ä»¶ - ä¿®å¤é…ç½®
            input_audio = gr.Audio(
                label="ä¸Šä¼ /å½•åˆ¶éŸ³é¢‘",
                sources=["upload", "microphone"],  # å¯ç”¨æ–‡ä»¶ä¸Šä¼ å’Œéº¦å…‹é£å½•åˆ¶
                type="numpy",  # è¿”å› (sample_rate, numpy_array) æ ¼å¼
                visible=False
            )

            quality_slider = gr.Slider(1, 30, value=15, label="å‹ç¼©è´¨é‡",
                                      info="æ•°å€¼è¶Šä½å‹ç¼©ç‡è¶Šé«˜ï¼Œå›¾åƒè´¨é‡è¶Šä½")
            encode_btn = gr.Button("è½¬æ¢ä¸ºæ–‡å­—", variant="primary")
            
        with gr.Column():
            # å­—æ•°ç»Ÿè®¡æ˜¾ç¤º
            char_count_display = gr.Number(label="å­—æ•°", interactive=False, value=0)

            output_text = gr.Textbox(label="åŠ å¯†æ–‡æœ¬", lines=10, elem_id="output-textbox",
                                    placeholder="è¿™é‡Œå°†æ˜¾ç¤ºå›¾ç‰‡/éŸ³é¢‘çš„åŠ å¯†æ–‡æœ¬...")
            copy_btn = gr.Button("å¤åˆ¶æ–‡æœ¬")

            # è§£ç å‚æ•°æ˜¾ç¤º
            decode_params = gr.Textbox(label="è§£ç å‚æ•°", interactive=False, visible=True, lines=5)
            
        with gr.Column():
            # å›¾ç‰‡è¾“å‡ºç»„ä»¶
            decoded_image = gr.Image(
                label="è§£ç é¢„è§ˆ (å›¾ç‰‡)", 
                interactive=False, 
                visible=True
            )
            
            # éŸ³é¢‘è¾“å‡ºç»„ä»¶ - ä¿®å¤é…ç½®
            decoded_audio = gr.Audio(
                label="è§£ç é¢„è§ˆ (éŸ³é¢‘)",
                interactive=False,  # åªç”¨äºæ’­æ”¾
                visible=False
            )
            
            decode_btn = gr.Button("ä»æ–‡æœ¬è¿˜åŸ", variant="secondary")

    # --- äº‹ä»¶å¤„ç† ---

    # åŠŸèƒ½åˆ‡æ¢é€»è¾‘ - ç®€åŒ–å’Œä¿®å¤
    def update_interface(mode):
        if mode == "å›¾ç‰‡ç¼–ç ":
            return [
                gr.update(visible=True),   # input_image
                gr.update(visible=False),  # input_audio  
                gr.update(visible=True),   # decoded_image
                gr.update(visible=False),  # decoded_audio
            ]
        else: # "éŸ³é¢‘ç¼–ç "
            return [
                gr.update(visible=False),  # input_image
                gr.update(visible=True),   # input_audio
                gr.update(visible=False),  # decoded_image  
                gr.update(visible=True),   # decoded_audio
            ]

    mode_selector.change(
        fn=update_interface,
        inputs=mode_selector,
        outputs=[input_image, input_audio, decoded_image, decoded_audio]
    )

    # å­—æ•°ç»Ÿè®¡é€»è¾‘
    output_text.change(
        fn=count_chars,
        inputs=output_text,
        outputs=char_count_display
    )

    # ç¼–ç é€»è¾‘ - ä¿®å¤è¾“å…¥å¤„ç†
    def encode_wrapper(mode, image_input, audio_input, quality):
        if mode == "å›¾ç‰‡ç¼–ç ":
            return image_to_text(image_input, quality)
        elif mode == "éŸ³é¢‘ç¼–ç ":
            if audio_input is None:
                return "é”™è¯¯: æœªæä¾›éŸ³é¢‘", ""
            return audio_to_text(audio_input, quality)
        else:
            return "é”™è¯¯: æœªçŸ¥æ¨¡å¼", ""

    encode_btn.click(
        fn=encode_wrapper,
        inputs=[mode_selector, input_image, input_audio, quality_slider],
        outputs=[output_text, decode_params]
    )

    # å¤åˆ¶æŒ‰é’®é€»è¾‘ (ä¿æŒä¸å˜)
    copy_btn.click(
        fn=None,
        inputs=output_text,
        outputs=None,
        js="(t) => { if (t) { navigator.clipboard.writeText(t); console.log('Text copied!'); } else { console.log('No text to copy'); } }"
    )

    # è§£ç é€»è¾‘ (æ™ºèƒ½è§£ç )
    decode_btn.click(
        fn=smart_decode,
        inputs=output_text,
        outputs=[decoded_image, decode_params, decoded_audio]
    )

    # å¤„ç†è¯´æ˜ (ä¿æŒä¸å˜)
    with gr.Accordion("å¤„ç†è¯´æ˜", open=False):
        gr.Markdown(f"""
        ### å›¾ç‰‡å¤„ç†ç­–ç•¥ (åŸºäºé¢ç§¯, æ— å¼ºåˆ¶å¡«å……)
        1. **é¢ç§¯åˆ¤æ–­**ï¼š
           - å›¾ç‰‡åˆ†è¾¨ç‡ï¼ˆå®½ x é«˜ï¼‰<= {MAX_PIXEL_AREA}ï¼š**ç›´æ¥å¤„ç†ï¼Œä¸è¿›è¡Œç¼©æ”¾æˆ–å¡«å……**ã€‚
           - å›¾ç‰‡åˆ†è¾¨ç‡ > {MAX_PIXEL_AREA}ï¼šç­‰æ¯”ä¾‹ç¼©æ”¾ï¼Œä½¿ç¼©æ”¾åé¢ç§¯ <= {MAX_PIXEL_AREA}ï¼Œ**ä¸è¿›è¡Œå¡«å……**ã€‚
        2. **ä¿æŒåŸå§‹æ¯”ä¾‹**ï¼š
           - ç¼©æ”¾æ—¶ä¸¥æ ¼ä¿æŒåŸå§‹å®½é«˜æ¯”ã€‚
           - **ä¸å†æ·»åŠ ç°è‰²è¾¹æ¡†å¡«å……**ã€‚
        3. **è‡ªé€‚åº”å‹ç¼©**ï¼š
           - å°å°ºå¯¸å›¾ç‰‡åŒºåŸŸï¼šä½¿ç”¨æ›´é«˜ç”»è´¨ã€‚
           - ç®€å•å›¾åƒï¼ˆå¦‚æ–‡å­—ï¼‰ï¼šå‡å°‘é¢œè‰²æ•°é‡ã€‚
           - å¤æ‚ç…§ç‰‡ï¼šé€‚å½“é™ä½ç”»è´¨ã€‚
        4. **ä¿¡æ¯å­˜å‚¨**ï¼š
           - å›¾ç‰‡ç¼–ç å¼€å¤´æ·»åŠ  `å“ˆåŸºç‰‡:å®½xé«˜|` ä¿¡æ¯ã€‚
           - è§£ç æ—¶ï¼Œå‚æ•°ä¿¡æ¯ä¼šæ˜¾ç¤ºåœ¨"è§£ç å‚æ•°"æ¡†ä¸­ã€‚

        ### éŸ³é¢‘å¤„ç†ç­–ç•¥ (åŸºäºé¢‘è°±å›¾)
        1. **é¢„å¤„ç†**ï¼š
           - éŸ³é¢‘è¢«é‡é‡‡æ ·åˆ° {AUDIO_SAMPLE_RATE}Hzã€‚
           - ä»…å¤„ç†å‰ {AUDIO_MAX_DURATION} ç§’ã€‚
           - è½¬æ¢ä¸ºå•å£°é“ã€‚
        2. **ç‰¹å¾æå–**ï¼š
           - æå– Mel é¢‘è°±å›¾ã€‚
           - è½¬æ¢ä¸ºå¯¹æ•°å¹…åº¦ã€‚
        3. **ç¼–ç **ï¼š
           - é¢‘è°±å›¾æ•°æ®è¢«åºåˆ—åŒ–ã€zlib å‹ç¼©ã€Base91 ç¼–ç ï¼Œå¹¶åº”ç”¨è‡ªå®šä¹‰å­—å…¸ã€‚
           - éŸ³é¢‘ç¼–ç å¼€å¤´æ·»åŠ  `å¤§ç‹—å«:æ—¶é•¿(ç§’)|` ä¿¡æ¯ã€‚
        4. **è§£ç **ï¼š
           - è§£ç æµç¨‹ä¸ºç¼–ç çš„é€†è¿‡ç¨‹ã€‚
           - ä½¿ç”¨ Griffin-Lim ç®—æ³•ä»é¢‘è°±å›¾é‡å»ºéŸ³é¢‘ã€‚
           - **æ³¨æ„**ï¼šç”±äºä¿¡æ¯æŸå¤±ï¼Œè§£ç åçš„éŸ³é¢‘ä¸åŸå§‹éŸ³é¢‘å¯èƒ½ä¸å®Œå…¨ç›¸åŒã€‚
        5. **ä¿¡æ¯å­˜å‚¨**ï¼š
           - éŸ³é¢‘ç¼–ç å¼€å¤´æ·»åŠ  `å¤§ç‹—å«:æ—¶é•¿(ç§’)|` ä¿¡æ¯ã€‚
           - è§£ç æ—¶ï¼Œå‚æ•°ä¿¡æ¯ä¼šæ˜¾ç¤ºåœ¨"è§£ç å‚æ•°"æ¡†ä¸­ã€‚
           - è§£ç åçš„éŸ³é¢‘å¯ä»¥ç›´æ¥åœ¨"è§£ç é¢„è§ˆ (éŸ³é¢‘)"ä¸­æ’­æ”¾ã€‚

        githubï¼šhttps://github.com/nvidiaxinec/multihajimi
        """)

# ==================== å¯åŠ¨åº”ç”¨ ====================
if __name__ == "__main__":
    app.launch()
	inbrowser=True # è‡ªåŠ¨åœ¨æµè§ˆå™¨æ‰“å¼€
	
