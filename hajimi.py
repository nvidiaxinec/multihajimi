import gradio as gr
from PIL import Image
import io
import zlib
import base91
import numpy as np
from math import sqrt, floor
import librosa
import soundfile as sf

# è‡ªå®šä¹‰å“ˆåŸºç±³å­—å…¸ (ä¿æŒä¸å˜)
CUSTOM_DICT = {
    'A': 'å“ˆ', 'B': 'è›¤', 'C': 'åŸº', 'D': 'é¸¡', 'E': 'å‡ ', 'F': 'å­£', 'G': 'é›†', 'H': 'å¯„',
    'I': 'å‰', 'J': 'æ£˜', 'K': 'è„Š', 'L': 'ç±³', 'M': 'å¯†', 'N': 'å’ª', 'O': 'è«', 'P': 'æ‘¸',
    'Q': 'è†œ', 'R': 'æŠ¹', 'S': 'æ¼ ', 'T': 'ç£¨', 'U': 'é™Œ', 'V': 'å¯', 'W': 'ç”·', 'X': 'å—',
    'Y': 'å–ƒ', 'Z': 'å¤', 'a': 'é‚£', 'b': 'å“ª', 'c': 'å‘', 'd': 'çº³', 'e': 'æ²¡', 'f': 'ç¾',
    'g': 'æ¯', 'h': 'ç»¿', 'i': 'è·¯', 'j': 'é¹¿', 'k': 'å½•', 'l': 'ä¸‹', 'm': 'è±†', 'n': 'é€—',
    'o': 'æ–—', 'p': 'å¤š', 'q': 'å“†', 'r': 'è·º', 's': 'æœµ', 't': 'å•Š', 'u': 'é˜¿', 'v': 'è¥¿',
    'w': 'ç³»', 'x': 'å™¶', 'y': 'å˜', 'z': 'å‘€', '0': 'å‹', '1': 'é›…', '2': 'äºš', '3': 'ä¸«',
    '4': 'åº“', '5': 'å“­', '6': 'é…·', '7': 'å¥¶', '8': 'ä¹ƒ', '9': 'å¥ˆ', '!': 'è€', '#': 'é¾™',
    '$': 'å’¯', '%': 'æ›¼', '&': 'æ³¢', '*': 'æ¼«', '(': 'å•µ', ')': 'å¶', '+': 'æ¬§', ',': 'å—',
    '"': 'é©¬', '.': 'å˜›', '/': 'é‡Œ', ':': 'åŠ›', '<': 'åˆ©', '=': 'ç†', '>': 'ä¸½',
    '?': 'å†', '@': 'ä¹Ÿ', '[': 'è€¶', '~': 'å¤§', ']': 'å“’', '^': 'è¾¾', '_': 'å—’', '`': 'ä¸',
    '{': 'å¸ƒ', '|': 'æ‰“', '}': 'å“‡', 'AA': 'å‘µ', 'BB': 'æŒ–', '9!': 'ccb', 'DD': 'å¸¦æ‰‹æœº', 'EE': 'å…´å¥‹å‰‚', 'FF': 'æ“é€¼', 'GG': 'ä¸€æ®µ', ':}': 'wow'
}
# åè½¬å­—å…¸ç”¨äºè§£ç  (ä¿æŒä¸å˜)
REVERSE_DICT = {v: k for k, v in CUSTOM_DICT.items()}

# --- ä¼˜åŒ–åçš„å¸¸é‡ (ä»æ–°ç‰ˆæœ¬ç§»æ¤) ---
MAX_PIXEL_AREA = 12000  # é™ä½æœ€å¤§é¢ç§¯ä»¥è·å¾—æ›´å¥½çš„å‹ç¼©

# --- éŸ³é¢‘å¤„ç†å¸¸é‡ ---
AUDIO_SAMPLE_RATE = 22050  # ç”¨äºé‡é‡‡æ ·çš„ç›®æ ‡é‡‡æ ·ç‡
AUDIO_N_FFT = 2048
AUDIO_HOP_LENGTH = 512
AUDIO_MAX_DURATION = 10.0 # æœ€å¤§å¤„ç†æ—¶é•¿ (ç§’)ï¼Œé˜²æ­¢è¿‡å¤§æ–‡ä»¶

# --- ä¼˜åŒ–åçš„å›¾ç‰‡å¤„ç†å‡½æ•° (ä»æ–°ç‰ˆæœ¬ç§»æ¤) ---

def smart_resize(image, target_area=MAX_PIXEL_AREA):
    """æ™ºèƒ½ç¼©æ”¾å›¾åƒ (ä¼˜åŒ–ç‰ˆæœ¬)"""
    # å¤„ç†ä¸åŒçš„æ•°æ®ç±»å‹
    if image.dtype != np.uint8:
        if image.dtype == np.float32 or image.dtype == np.float64:
            image = np.clip(image * 255, 0, 255).astype(np.uint8)
        else:
            image = np.clip((image / np.max(image)) * 255, 0, 255).astype(np.uint8)
            
    img = Image.fromarray(image, 'RGB')
    original_w, original_h = img.size
    original_area = original_w * original_h
    if original_area <= target_area:
        print(f"å›¾ç‰‡å°ºå¯¸åˆé€‚ ({original_w}x{original_h})ï¼Œä½¿ç”¨åŸå§‹å°ºå¯¸")
        return img, (original_w, original_h)
    else:
        # æ·»åŠ 0.95çš„å®‰å…¨ç³»æ•°ç¡®ä¿ä¸è¶…è¿‡é™åˆ¶
        scale_factor = sqrt(target_area / original_area) * 0.95
        new_w = max(1, floor(original_w * scale_factor))
        new_h = max(1, floor(original_h * scale_factor))
        resized_img = img.resize((new_w, new_h), Image.LANCZOS)
        print(f"å›¾ç‰‡ä» ({original_w}x{original_h}) ç¼©æ”¾ä¸º ({new_w}x{new_h})")
        return resized_img, (original_w, original_h)

def rle_compress_colors(image_pil):
    """å¯¹çº¯è‰²åŒºåŸŸè¿›è¡ŒRLEå‹ç¼©é¢„å¤„ç† (æ–°å¢ä¼˜åŒ–)"""
    np_img = np.array(image_pil)
    diff_threshold = 10
    height, width, channels = np_img.shape
    for y in range(height):
        for x in range(width-1):
            if np.abs(np_img[y, x] - np_img[y, x+1]).max() < diff_threshold:
                np_img[y, x+1] = np_img[y, x]
    return Image.fromarray(np_img)

def adaptive_compress(image_pil, quality=15):
    """ä¼˜åŒ–çš„è‡ªé€‚åº”å‹ç¼© (å¢å¼ºç‰ˆæœ¬)"""
    # å…ˆè¿›è¡ŒRLEé¢„å¤„ç†
    img = rle_compress_colors(image_pil)
    w, h = img.size
    np_img = np.array(img)
    
    # è®¡ç®—å›¾åƒå¤æ‚åº¦
    diff_x = np.abs(np_img[:, 1:] - np_img[:, :-1]).mean()
    diff_y = np.abs(np_img[1:, :] - np_img[:-1, :]).mean()
    complexity = (diff_x + diff_y) / 2

    # æ›´ç²¾ç»†çš„é¢œè‰²é‡åŒ–ç­–ç•¥
    if w * h < 5000:
        colors = 128
    elif complexity < 5:
        colors = 32  # ç®€å•å›¾åƒä½¿ç”¨æ›´å°‘é¢œè‰²
    elif complexity < 15:
        colors = 64
    else:
        colors = 96  # å¤æ‚å›¾åƒé€‚å½“å‡å°‘é¢œè‰²

    # é¢œè‰²é‡åŒ–
    if colors < 256:
        img = img.quantize(colors=colors, method=Image.MEDIANCUT, dither=Image.FLOYDSTEINBERG)
        img = img.convert('RGB')

    buffer = io.BytesIO()
    try:
        # ä¼˜å…ˆä½¿ç”¨WEBPæ ¼å¼ï¼Œæ·»åŠ æ›´å¤šä¼˜åŒ–å‚æ•°
        img.save(buffer, format='WEBP', quality=quality, method=6, optimize=True, lossless=False)
    except Exception as e:
        print(f"WEBPç¼–ç å¤±è´¥ï¼Œä½¿ç”¨JPEG: {e}")
        buffer = io.BytesIO()
        img.save(buffer, format='JPEG', quality=quality, optimize=True)
    
    compressed_img = buffer.getvalue()
    return compressed_img, quality, colors

def image_to_text(image, quality=15):
    """å°†å›¾ç‰‡è½¬æ¢ä¸ºæ–‡æœ¬ç¼–ç  (ä½¿ç”¨ä¼˜åŒ–çš„å¤„ç†å‡½æ•°)"""
    if image is None:
         return "é”™è¯¯: æœªæä¾›å›¾ç‰‡", ""
    try:
        # ä½¿ç”¨ä¼˜åŒ–åçš„å¤„ç†å‡½æ•°
        processed_img_pil, orig_size = smart_resize(image, target_area=MAX_PIXEL_AREA)
        compressed_data, used_quality, used_colors = adaptive_compress(processed_img_pil, quality)
        
        # ä¿æŒåŸæœ‰çš„ç¼–ç æµç¨‹
        zlib_compressed = zlib.compress(compressed_data, level=9)
        base91_str = base91.encode(zlib_compressed)

        text_data = base91_str
        for pattern in sorted(CUSTOM_DICT.keys(), key=len, reverse=True):
            text_data = text_data.replace(pattern, CUSTOM_DICT[pattern])

        size_prefix = f"å“ˆåŸºç‰‡:{orig_size[0]}x{orig_size[1]}|"
        
        # è°ƒæ•´æ¯è¡Œå­—ç¬¦æ•°ä»¥è·å¾—æ›´å¥½çš„æ˜¾ç¤ºæ•ˆæœ
        lines = [text_data[i:i+40] for i in range(0, len(text_data), 40)]
        formatted_text = "\n".join(lines)
        
        # è¿”å›è¯¦ç»†çš„å‹ç¼©ä¿¡æ¯
        param_info = f"å‹ç¼©è´¨é‡: {used_quality}\né¢œè‰²æ•°: {used_colors}\nWebPå¤§å°: {len(compressed_data)} å­—èŠ‚\nZlibå‹ç¼©å: {len(zlib_compressed)} å­—èŠ‚\nå‹ç¼©æ¯”: {len(compressed_data)/len(zlib_compressed):.2f}"
        return size_prefix + formatted_text, param_info
        
    except Exception as e:
        gr.Error(f"å›¾ç‰‡ç¼–ç å¤±è´¥: {e}")
        return f"é”™è¯¯: {e}", ""

def text_to_image(text_data):
    """å°†æ–‡æœ¬ç¼–ç è¿˜åŸä¸ºå›¾ç‰‡ (ä¿æŒåŸæœ‰é€»è¾‘)"""
    if not text_data or not text_data.strip():
        gr.Warning("è¾“å…¥çš„åŠ å¯†æ–‡æœ¬ä¸ºç©ºã€‚")
        return None, "é”™è¯¯: è¾“å…¥ä¸ºç©º"

    param_info_str = "è§£ç ä¸­..."
    orig_w = "æœªçŸ¥"
    orig_h = "æœªçŸ¥"
    processed_w = "æœªçŸ¥"
    processed_h = "æœªçŸ¥"

    clean_text_for_decoding = text_data
    if text_data.startswith("å“ˆåŸºç‰‡:"):
        parts = text_data.split("|", 1)
        if len(parts) == 2:
            size_info_part = parts[0]
            text_data_body = parts[1]
            try:
                _, size_str = size_info_part.split(":", 1)
                orig_w_str, orig_h_str = size_str.split("x", 1)
                orig_w = int(orig_w_str)
                orig_h = int(orig_h_str)
                param_info_str = f"åŸå§‹å°ºå¯¸: {orig_w}x{orig_h}\n"
            except (ValueError, IndexError) as e:
                 gr.Warning(f"åŠ å¯†æ–‡æœ¬ä¸­çš„å°ºå¯¸ä¿¡æ¯æ ¼å¼ä¸æ­£ç¡®: {e}")
                 param_info_str = "å°ºå¯¸ä¿¡æ¯è§£æå¤±è´¥\n"
            clean_text_for_decoding = text_data_body
        else:
            gr.Warning("åŠ å¯†æ–‡æœ¬æ ¼å¼é”™è¯¯ï¼šå‘ç°'å“ˆåŸºç‰‡:'å‰ç¼€ä½†ç¼ºå°‘åˆ†éš”ç¬¦'|'ã€‚")
            param_info_str = "æ ¼å¼é”™è¯¯: ç¼ºå°‘åˆ†éš”ç¬¦\n"

    clean_text = clean_text_for_decoding.replace("\n", "").replace(" ", "")
    if not clean_text:
        error_msg = "é”™è¯¯: å¤„ç†åçš„åŠ å¯†æ–‡æœ¬ä¸»ä½“ä¸ºç©ºã€‚"
        gr.Error(error_msg)
        return None, param_info_str + error_msg

    temp_text = clean_text
    for char, pattern in REVERSE_DICT.items():
        temp_text = temp_text.replace(char, pattern)
    clean_text = temp_text

    try:
        zlib_data = base91.decode(clean_text)
    except Exception as e:
        error_msg = f"Base91è§£ç å¤±è´¥: {str(e)}"
        gr.Error(error_msg)
        return None, param_info_str + error_msg

    try:
        webp_data = zlib.decompress(zlib_data)
    except Exception as e:
        error_msg = f"zlibè§£å‹å¤±è´¥: {str(e)}ã€‚è¾“å…¥æ–‡æœ¬å¯èƒ½å·²æŸåæˆ–ä¸å®Œæ•´ã€‚"
        gr.Error(error_msg)
        return None, param_info_str + error_msg

    try:
        img = Image.open(io.BytesIO(webp_data))
        img = img.convert('RGB')
        processed_w, processed_h = img.size
        final_param_info = param_info_str + f"å¤„ç†åå°ºå¯¸: {processed_w}x{processed_h}\nè§£ç æˆåŠŸ!"
        return np.array(img), final_param_info
    except Exception as e:
        error_msg = f"æ— æ³•é‡å»ºå›¾åƒ: {str(e)}"
        gr.Error(error_msg)
        return None, param_info_str + error_msg

# --- éŸ³é¢‘å¤„ç†å‡½æ•° (ä¿æŒåŸæœ‰é€»è¾‘) ---

def audio_to_text(audio_tuple, quality=15):
    """å°†éŸ³é¢‘è½¬æ¢ä¸ºæ–‡æœ¬ç¼–ç """
    if audio_tuple is None:
        return "é”™è¯¯: æœªæä¾›éŸ³é¢‘", ""
    try:
        # audio_tuple æ˜¯ (sample_rate, audio_data)
        orig_sr, audio_data = audio_tuple
        # ç¡®ä¿æ˜¯å•å£°é“
        if audio_data.ndim > 1:
            audio_data = audio_data[:, 0] # å–ç¬¬ä¸€ä¸ªå£°é“

        # é™åˆ¶æ—¶é•¿
        max_samples = int(AUDIO_MAX_DURATION * orig_sr)
        if len(audio_data) > max_samples:
             gr.Info(f"éŸ³é¢‘è¿‡é•¿ï¼Œä»…å¤„ç†å‰ {AUDIO_MAX_DURATION} ç§’ã€‚")
             audio_data = audio_data[:max_samples]

        # é‡é‡‡æ ·
        audio_float = audio_data.astype(np.float32)
        if np.max(np.abs(audio_data)) > 0:
            audio_float = audio_float / np.max(np.abs(audio_data))
        audio_resampled = librosa.resample(y=audio_float, orig_sr=orig_sr, target_sr=AUDIO_SAMPLE_RATE)

        # è½¬æ¢ä¸ºé¢‘è°±å›¾ (ä¾‹å¦‚ Mel é¢‘è°±)
        mel_spec = librosa.feature.melspectrogram(y=audio_resampled, sr=AUDIO_SAMPLE_RATE, n_fft=AUDIO_N_FFT, hop_length=AUDIO_HOP_LENGTH)
        # è½¬æ¢ä¸ºå¯¹æ•°å¹…åº¦
        log_mel_spec = librosa.power_to_db(mel_spec, ref=np.max)

        # åºåˆ—åŒ–ä¸ºå­—èŠ‚
        spec_bytes = log_mel_spec.tobytes()

        # å‹ç¼©
        zlib_compressed = zlib.compress(spec_bytes, level=9)
        # Base91ç¼–ç 
        base91_str = base91.encode(zlib_compressed)

        # åº”ç”¨è‡ªå®šä¹‰å­—å…¸æ›¿æ¢
        text_data = base91_str
        for pattern in sorted(CUSTOM_DICT.keys(), key=len, reverse=True):
            text_data = text_data.replace(pattern, CUSTOM_DICT[pattern])

        # æ·»åŠ æ—¶é•¿ä¿¡æ¯å‰ç¼€
        duration = len(audio_resampled) / AUDIO_SAMPLE_RATE
        duration_prefix = f"å¤§ç‹—å«:{duration:.2f}s|"

        # æ ¼å¼åŒ–è¾“å‡º
        lines = [text_data[i:i+24] for i in range(0, len(text_data), 24)]
        formatted_text = "\n".join(lines)

        param_info = f"éŸ³é¢‘æ—¶é•¿: {duration:.2f}s\né‡‡æ ·ç‡: {AUDIO_SAMPLE_RATE}Hz\nFFTå¤§å°: {AUDIO_N_FFT}\nHopé•¿åº¦: {AUDIO_HOP_LENGTH}"
        return duration_prefix + formatted_text, param_info
    except Exception as e:
        gr.Error(f"éŸ³é¢‘ç¼–ç å¤±è´¥: {e}")
        return f"é”™è¯¯: {e}", ""

def text_to_audio(text_data):
    """å°†æ–‡æœ¬ç¼–ç è¿˜åŸä¸ºéŸ³é¢‘ (ç®€åŒ–ç‰ˆï¼Œä»…æ¼”ç¤ºæµç¨‹)"""
    if not text_data or not text_data.strip():
        gr.Warning("è¾“å…¥çš„åŠ å¯†æ–‡æœ¬ä¸ºç©ºã€‚")
        return None, "é”™è¯¯: è¾“å…¥ä¸ºç©º"

    param_info_str = "è§£ç ä¸­..."
    duration = "æœªçŸ¥"

    clean_text_for_decoding = text_data
    if text_data.startswith("å¤§ç‹—å«:"):
        parts = text_data.split("|", 1)
        if len(parts) == 2:
            size_info_part = parts[0]
            text_data_body = parts[1]
            try:
                _, duration_str = size_info_part.split(":", 1)
                duration = duration_str.replace("s", "") # ç§»é™¤ 's'
                duration = float(duration)
                param_info_str = f"éŸ³é¢‘æ—¶é•¿: {duration:.2f}s\n"
            except (ValueError, IndexError) as e:
                 gr.Warning(f"åŠ å¯†æ–‡æœ¬ä¸­çš„æ—¶é•¿ä¿¡æ¯æ ¼å¼ä¸æ­£ç¡®: {e}")
                 param_info_str = "æ—¶é•¿ä¿¡æ¯è§£æå¤±è´¥\n"
            clean_text_for_decoding = text_data_body
        else:
            gr.Warning("åŠ å¯†æ–‡æœ¬æ ¼å¼é”™è¯¯ï¼šå‘ç°'å¤§ç‹—å«:'å‰ç¼€ä½†ç¼ºå°‘åˆ†éš”ç¬¦'|'ã€‚")
            param_info_str = "æ ¼å¼é”™è¯¯: ç¼ºå°‘åˆ†éš”ç¬¦\n"

    clean_text = clean_text_for_decoding.replace("\n", "").replace(" ", "")
    if not clean_text:
        error_msg = "é”™è¯¯: å¤„ç†åçš„åŠ å¯†æ–‡æœ¬ä¸»ä½“ä¸ºç©ºã€‚"
        gr.Error(error_msg)
        return None, param_info_str + error_msg

    temp_text = clean_text
    for char, pattern in REVERSE_DICT.items():
        temp_text = temp_text.replace(char, pattern)
    clean_text = temp_text

    try:
        zlib_data = base91.decode(clean_text)
    except Exception as e:
        error_msg = f"Base91è§£ç å¤±è´¥: {str(e)}"
        gr.Error(error_msg)
        return None, param_info_str + error_msg

    try:
        spec_bytes = zlib.decompress(zlib_data)
    except Exception as e:
        error_msg = f"zlibè§£å‹å¤±è´¥: {str(e)}ã€‚è¾“å…¥æ–‡æœ¬å¯èƒ½å·²æŸåæˆ–ä¸å®Œæ•´ã€‚"
        gr.Error(error_msg)
        return None, param_info_str + error_msg

    try:
        # ä»å­—èŠ‚é‡å»ºé¢‘è°±å›¾å½¢çŠ¶ (è¿™é‡Œéœ€è¦çŸ¥é“åŸå§‹å½¢çŠ¶ï¼Œç®€åŒ–å¤„ç†)
        # å®é™…åº”ç”¨ä¸­å¯èƒ½éœ€è¦åœ¨ç¼–ç æ—¶å­˜å‚¨é¢‘è°±å›¾çš„å½¢çŠ¶ä¿¡æ¯
        # è¿™é‡Œå‡è®¾ä¸€ä¸ªå…¸å‹çš„å½¢çŠ¶ (ä¾‹å¦‚ 128 é¢‘æ®µ, 44 ä¸ªæ—¶é—´å¸§)
        # æ³¨æ„ï¼šè¿™ä¼šå¯¼è‡´è§£ç åçš„éŸ³é¢‘ä¸åŸå§‹éŸ³é¢‘ä¸å®Œå…¨ä¸€è‡´ï¼Œä»…ç”¨äºæ¼”ç¤º
        spec_shape = (128, 44) # ç¤ºä¾‹å½¢çŠ¶
        log_mel_spec_flat = np.frombuffer(spec_bytes, dtype=np.float32)
        if log_mel_spec_flat.size != np.prod(spec_shape):
             # å°è¯•æ ¹æ®å­—èŠ‚æ•°æ¨æ–­ (å¯èƒ½ä¸å‡†ç¡®)
             expected_size = len(spec_bytes) // 4 # float32 is 4 bytes
             spec_shape = (128, expected_size // 128) # ç®€å•ä¼°ç®—
             if spec_shape[0] * spec_shape[1] * 4 != len(spec_bytes):
                  raise ValueError("æ— æ³•æ¨æ–­é¢‘è°±å›¾å½¢çŠ¶")

        log_mel_spec = log_mel_spec_flat.reshape(spec_shape)

        # è½¬æ¢å›å¹…åº¦è°±
        mel_spec = librosa.db_to_power(log_mel_spec)

        # Griffin-Lim ç®—æ³•é‡å»ºéŸ³é¢‘
        audio_reconstructed = librosa.feature.inverse.mel_to_audio(mel_spec, sr=AUDIO_SAMPLE_RATE, n_fft=AUDIO_N_FFT, hop_length=AUDIO_HOP_LENGTH)

        # è½¬æ¢ä¸º Gradio éœ€è¦çš„æ ¼å¼ (é‡‡æ ·ç‡, éŸ³é¢‘æ•°æ®)
        # Gradio æœŸæœ› int16 ç±»å‹çš„æ•°æ®
        audio_int16 = (audio_reconstructed * 32767).astype(np.int16)

        final_param_info = param_info_str + f"é‡‡æ ·ç‡: {AUDIO_SAMPLE_RATE}Hz\nè§£ç æˆåŠŸ (æ³¨æ„: ä¸ºæ¼”ç¤ºï¼Œå¯èƒ½ä¸åŸéŸ³é¢‘ä¸åŒ)!"
        return (AUDIO_SAMPLE_RATE, audio_int16), final_param_info
    except Exception as e:
        error_msg = f"æ— æ³•é‡å»ºéŸ³é¢‘: {str(e)}"
        gr.Error(error_msg)
        return None, param_info_str + error_msg

# --- æ™ºèƒ½è§£ç å‡½æ•° ---
def smart_decode(text_data):
    """æ ¹æ®å‰ç¼€æ™ºèƒ½åˆ¤æ–­å¹¶è°ƒç”¨è§£ç å‡½æ•°"""
    if not text_data or not text_data.strip():
        return None, "é”™è¯¯: è¾“å…¥ä¸ºç©º", None

    clean_text = text_data.strip()
    if clean_text.startswith("å“ˆåŸºç‰‡:"):
        img, param_info = text_to_image(clean_text)
        return img, param_info, None # è¿”å›å›¾ç‰‡, å‚æ•°ä¿¡æ¯, éŸ³é¢‘(æ— )
    elif clean_text.startswith("å¤§ç‹—å«:"):
        audio, param_info = text_to_audio(clean_text)
        return None, param_info, audio # è¿”å›å›¾ç‰‡(æ— ), å‚æ•°ä¿¡æ¯, éŸ³é¢‘
    else:
        # å¦‚æœæ²¡æœ‰æ˜ç¡®å‰ç¼€ï¼Œå¯ä»¥å°è¯•åˆ¤æ–­æˆ–æŠ¥é”™
        # è¿™é‡Œç®€å•æŠ¥é”™
        gr.Warning("æ— æ³•è¯†åˆ«æ–‡æœ¬ç±»å‹ï¼Œè¯·ç¡®ä¿æ–‡æœ¬ä»¥ 'å“ˆåŸºç‰‡:' æˆ– 'å¤§ç‹—å«:' å¼€å¤´ã€‚")
        return None, "é”™è¯¯: æ— æ³•è¯†åˆ«çš„æ–‡æœ¬ç±»å‹", None

# --- å­—æ•°ç»Ÿè®¡å‡½æ•° ---
def count_chars(text):
    """è®¡ç®—æ–‡æœ¬ä¸­çš„å­—ç¬¦æ•°ï¼ˆä¸åŒ…æ‹¬æ¢è¡Œç¬¦ï¼‰"""
    if not text:
        return 0
    return len(text.replace('\n', ''))

# ==================== Gradio ç•Œé¢å®šä¹‰ ====================
with gr.Blocks(title="å“ˆåŸºç±³å›¾ç‰‡/éŸ³é¢‘ç¼–ç å™¨ - V 0.2.0", theme=gr.themes.Soft()) as app:
    gr.Markdown("## ğŸ± å“ˆåŸºç±³å›¾ç‰‡/éŸ³é¢‘ç¼–ç å™¨ - V 0.2.0")
    gr.Markdown("ä¸Šä¼ å›¾ç‰‡æˆ–éŸ³é¢‘ï¼Œæ™ºèƒ½å¤„ç†å¹¶è½¬æ¢ä¸ºæœ‰è¶£çš„æ–‡å­—ç¼–ç ï¼**å›¾ç‰‡å‹ç¼©å·²ä¼˜åŒ–ï¼Œæ–‡å­—æ•°é‡æ›´å°‘ï¼**")

    # åŠŸèƒ½é€‰æ‹©
    mode_selector = gr.Radio(
        choices=["å›¾ç‰‡ç¼–ç ", "éŸ³é¢‘ç¼–ç "],
        value="å›¾ç‰‡ç¼–ç ",
        label="é€‰æ‹©åŠŸèƒ½"
    )

    with gr.Row():
        with gr.Column():
            # å›¾ç‰‡è¾“å…¥ç»„ä»¶
            input_image = gr.Image(
                label="ä¸Šä¼ å›¾ç‰‡", 
                type="numpy", 
                visible=True
            )
            
            # éŸ³é¢‘è¾“å…¥ç»„ä»¶ - ä¿®å¤é…ç½®
            input_audio = gr.Audio(
                label="ä¸Šä¼ /å½•åˆ¶éŸ³é¢‘",
                sources=["upload", "microphone"],  # å¯ç”¨æ–‡ä»¶ä¸Šä¼ å’Œéº¦å…‹é£å½•åˆ¶
                type="numpy",  # è¿”å› (sample_rate, numpy_array) æ ¼å¼
                visible=False
            )

            quality_slider = gr.Slider(1, 30, value=15, label="å‹ç¼©è´¨é‡",
                                      info="æ•°å€¼è¶Šä½å‹ç¼©ç‡è¶Šé«˜ï¼Œå›¾åƒè´¨é‡è¶Šä½")
            encode_btn = gr.Button("è½¬æ¢ä¸ºæ–‡å­—", variant="primary")
            
        with gr.Column():
            # å­—æ•°ç»Ÿè®¡æ˜¾ç¤º
            char_count_display = gr.Number(label="å­—æ•°", interactive=False, value=0)

            # å‹ç¼©ä¿¡æ¯æ˜¾ç¤º
            compression_info = gr.Textbox(
                label="å‹ç¼©ä¿¡æ¯", 
                interactive=False, 
                lines=4,
                placeholder="å‹ç¼©ç»Ÿè®¡ä¿¡æ¯å°†æ˜¾ç¤ºåœ¨è¿™é‡Œ..."
            )

            output_text = gr.Textbox(label="åŠ å¯†æ–‡æœ¬", lines=10, elem_id="output-textbox",
                                    placeholder="è¿™é‡Œå°†æ˜¾ç¤ºå›¾ç‰‡/éŸ³é¢‘çš„åŠ å¯†æ–‡æœ¬...")
            copy_btn = gr.Button("ğŸ“‹ å¤åˆ¶æ–‡æœ¬")

            # è§£ç å‚æ•°æ˜¾ç¤º
            decode_params = gr.Textbox(label="è§£ç å‚æ•°", interactive=False, visible=True, lines=5)
            
        with gr.Column():
            # å›¾ç‰‡è¾“å‡ºç»„ä»¶
            decoded_image = gr.Image(
                label="è§£ç é¢„è§ˆ (å›¾ç‰‡)", 
                interactive=False, 
                visible=True
            )
            
            # éŸ³é¢‘è¾“å‡ºç»„ä»¶ - ä¿®å¤é…ç½®
            decoded_audio = gr.Audio(
                label="è§£ç é¢„è§ˆ (éŸ³é¢‘)",
                interactive=False,  # åªç”¨äºæ’­æ”¾
                visible=False
            )
            
            decode_btn = gr.Button("ğŸ”„ ä»æ–‡æœ¬è¿˜åŸ", variant="secondary")

    # --- äº‹ä»¶å¤„ç† ---

    # åŠŸèƒ½åˆ‡æ¢é€»è¾‘ - ç®€åŒ–å’Œä¿®å¤
    def update_interface(mode):
        if mode == "å›¾ç‰‡ç¼–ç ":
            return [
                gr.update(visible=True),   # input_image
                gr.update(visible=False),  # input_audio  
                gr.update(visible=True),   # decoded_image
                gr.update(visible=False),  # decoded_audio
            ]
        else: # "éŸ³é¢‘ç¼–ç "
            return [
                gr.update(visible=False),  # input_image
                gr.update(visible=True),   # input_audio
                gr.update(visible=False),  # decoded_image  
                gr.update(visible=True),   # decoded_audio
            ]

    mode_selector.change(
        fn=update_interface,
        inputs=mode_selector,
        outputs=[input_image, input_audio, decoded_image, decoded_audio]
    )

    # å­—æ•°ç»Ÿè®¡é€»è¾‘
    output_text.change(
        fn=count_chars,
        inputs=output_text,
        outputs=char_count_display
    )

    # ç¼–ç é€»è¾‘ - ä¿®å¤è¾“å…¥å¤„ç†
    def encode_wrapper(mode, image_input, audio_input, quality):
        if mode == "å›¾ç‰‡ç¼–ç ":
            result_text, param_info = image_to_text(image_input, quality)
            compression_info_text = f"å›¾ç‰‡ç¼–ç å®Œæˆ\n{param_info}"
            return result_text, param_info, compression_info_text
        elif mode == "éŸ³é¢‘ç¼–ç ":
            if audio_input is None:
                return "é”™è¯¯: æœªæä¾›éŸ³é¢‘", "", "é”™è¯¯: æœªæä¾›éŸ³é¢‘"
            result_text, param_info = audio_to_text(audio_input, quality)
            compression_info_text = f"éŸ³é¢‘ç¼–ç å®Œæˆ\n{param_info}"
            return result_text, param_info, compression_info_text
        else:
            return "é”™è¯¯: æœªçŸ¥æ¨¡å¼", "", "é”™è¯¯: æœªçŸ¥æ¨¡å¼"

    encode_btn.click(
        fn=encode_wrapper,
        inputs=[mode_selector, input_image, input_audio, quality_slider],
        outputs=[output_text, decode_params, compression_info]
    )

    # å¤åˆ¶æŒ‰é’®é€»è¾‘ (ä¿æŒä¸å˜)
    copy_btn.click(
        fn=None,
        inputs=output_text,
        outputs=None,
        js="(t) => { if (t) { navigator.clipboard.writeText(t); console.log('Text copied to clipboard!'); alert('æ–‡æœ¬å·²å¤åˆ¶åˆ°å‰ªè´´æ¿!'); } else { alert('æ²¡æœ‰æ–‡æœ¬å¯å¤åˆ¶!'); } }"
    )

    # è§£ç é€»è¾‘ (æ™ºèƒ½è§£ç )
    def decode_wrapper(text_input):
        try:
            img, param_info, audio = smart_decode(text_input)
            return img, param_info, audio
        except Exception as e:
            error_msg = f"è§£ç è¿‡ç¨‹å‘ç”Ÿæœªé¢„æœŸé”™è¯¯: {e}"
            gr.Error(error_msg)
            return None, error_msg, None

    decode_btn.click(
        fn=decode_wrapper,
        inputs=output_text,
        outputs=[decoded_image, decode_params, decoded_audio]
    )

    # å¤„ç†è¯´æ˜
    with gr.Accordion("ä¼˜åŒ–è¯´æ˜", open=False):
        gr.Markdown(f"""
        ### ğŸš€ æœ¬ç‰ˆæœ¬çš„ä¼˜åŒ–å†…å®¹ï¼š
        
        **å›¾ç‰‡å¤„ç†ä¼˜åŒ–ï¼š**
        1. **é™ä½æœ€å¤§é¢ç§¯**: ä» 16384 é™è‡³ {MAX_PIXEL_AREA}ï¼Œæ˜¾è‘—å‡å°‘æ–‡å­—æ•°é‡
        2. **RLEé¢„å¤„ç†**: å¯¹ç›¸ä¼¼é¢œè‰²åŒºåŸŸè¿›è¡Œé¢„å¤„ç†ï¼Œæé«˜å‹ç¼©æ•ˆç‡
        3. **æ™ºèƒ½é¢œè‰²é‡åŒ–**: æ ¹æ®å›¾åƒå¤æ‚åº¦åŠ¨æ€è°ƒæ•´é¢œè‰²æ•°é‡
        4. **ä¼˜åŒ–WEBPå‚æ•°**: ä½¿ç”¨æ›´å¥½çš„å‹ç¼©å‚æ•°ï¼Œå‡å°æ–‡ä»¶ä½“ç§¯
        5. **æ›´é•¿çš„æ–‡æœ¬è¡Œ**: æ¯è¡Œ40å­—ç¬¦ï¼ˆåŸæ¥24ï¼‰ï¼Œå‡å°‘æ¢è¡Œç¬¦æ•°é‡
        6. **è¯¦ç»†å‹ç¼©ä¿¡æ¯**: æ˜¾ç¤ºå®Œæ•´çš„å‹ç¼©ç»Ÿè®¡æ•°æ®
       
        
        **é¢„æœŸæ•ˆæœï¼š**
        - åŒç­‰è´¨é‡å›¾ç‰‡çš„æ–‡å­—æ•°é‡å‡å°‘çº¦ 20-40%
        - ä¿æŒ100%çš„ç¼–ç /è§£ç å…¼å®¹æ€§
        
        **ä½¿ç”¨å»ºè®®ï¼š**
        - ç®€å•å›¾ç‰‡ï¼ˆå¦‚æˆªå›¾ã€æ–‡å­—å›¾ç‰‡ï¼‰å¯ä»¥ä½¿ç”¨è¾ƒä½è´¨é‡è®¾ç½®ï¼ˆ5-10ï¼‰
        - å¤æ‚ç…§ç‰‡å»ºè®®ä½¿ç”¨ä¸­ç­‰è´¨é‡è®¾ç½®ï¼ˆ15-25ï¼‰
        - å¦‚éœ€æœ€å°æ–‡å­—æ•°é‡ï¼Œå¯å°è¯•è´¨é‡1-5
        - githubï¼šhttps://github.com/nvidiaxinec/multihajimi
        """)

# ==================== å¯åŠ¨åº”ç”¨ ====================
if __name__ == "__main__":
    app.launch(inbrowser=True)